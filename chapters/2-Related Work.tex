ReMLOFT is built using the insights of traditional knowledge graphs for question answering and existing approaches on relation mapping for natural language questions. This chapter reviews related work on knowledge graphs, questioning answering systems, interactive systems and relation mapping on natural language questions.

\section{Knowledge Graphs}
Knowledge Graphs are the backbone of the next-generation search and help users discover new information quickly and easily. 
At the heart of modern intelligent systems, the knowledge graphs provide an enormous knowledge reserve and support for intelligent information processing. It has been widely used in medicine, recommender systems and marketing and has very large prospects. Knowledge graphs could be cross-domain or domain-specific. 
Knowledge graphs are additionally categorized into three categories, i.e., \textit{common-sense KGs}: that contain knowledge about the everyday world, \textit{factual KGs}: containing knowledge about facts and events, and \textit{domain KGs}: that encode knowledge from a specific area (linguistics, scientific, biomedical, geographical etc.) \cite{TIDDI2022103627}.
Several knowledge graphs have been made available on the Web in recent years. The most adopted KGs in the literature are publicly available or crowdsourced. Some Enterprise Knowledge Graphs (EKGs), knowledge graphs sourced by large corporations, have been created in the latest years – Google’s \footnotemark[\ref{google}] and Facebook’s social Knowledge Graph, Amazon’s and Ebay’s Product Graphs \cite{TIDDI2022103627}. Examples of popular knowledge graphs used in research are WikiData\cite{wikidata}, DBpedia\cite{dbpedia}, YAGO\cite{yago}, WordNet\cite{wordnet}, Freebase\cite{freebase} (discontinued in 2017) and OpenCyc\footnote{http://www.cyc.com/} (discontinued in 2015). 

WikiData is also a free, collaborative, multilingual, structured project built on top of wiki contents including Wikipedia, Wikivoyage, Wiktionary, Wikisource, etc.\footnote{https://www.wikidata.org/}

DBpedia is a knowledge graph that is extracted from structured data in Wikipedia. The main source for this extraction is the key-value pairs in the Wikipedia infoboxes. It contains 228 million entities, 768 classes and 3000 properties of large cross-domain ontology\footnote{\label{dbp}https://www.dbpedia.org}.

YAGO combines Wikidata and schema.org and contains more than 50 million entities and 2 billion facts\footnote{https://yago-knowledge.org}. 
% YAGO is stored in the standard Resource Description Framework - RDF, each of which consists of a subject, a predicate and an object.

WordNet is a curated lexical database of relationships between concepts (hypernyms, pertainyms, meronyms, etc.).

Advanced AI systems are driven by knowledge graphs, which allows single queries to be turned into an ongoing conversation.
This enables a user to communicate with the system while the system keeps track of the context through each phase of the conversation \cite{Industry-Scale}.

\section{Question Answering using Knowledge Graphs}
Question answering over knowledge graphs aims to use facts in the knowledge graph (KG) to answer natural language questions. 
They provide crisp answers to questions by translating them to precise structured queries over the knowledge graph. A major challenge in a QA system is matching the natural language expressions and the complex schema of the knowledge graph. Consider the question, \textit{"Give me all actors who were born in Paris after 1950."}, which invloves concepts such as "actors", "birthDate" and "birthPlace", that are not easy to map to a structured search over the queried dataset (DBpedia), in addition to requiring a conditional comparison of the results. 

Simple QA links entities to a single relation in the KG. Each question
can acquire the answer from a single fact in the knowledge graph.

As a result, existing methods focus on simple questions answerable with one main relation path in the KG and struggle with complex questions that require joining multiple relations. 
% simple question answering
Some QA systems have achieved good performance on simple questions, i.e., those questions which can be answered by linking to at most one relation and at most one entity in the KG. Lukonikov, et al \cite{10.1145/3038912.3052675}, propose an end-to-end neural network approach that generates a solution for simple questions, which requires the retrieval of a single fact to be answered. They build a knowledge graph-independent representation of entities and relations from textual information associated with the entities or relations. They perform a thorough error analysis that mentions the different types of errors in a QA system like \textit{missing candidates, indistinguishability, hard and soft ambiguity, wrong subject and relation detection}.

Huang, et al \cite{10.1145/3289600.3290956} also focus on simple questions, using a Knowledge Embedding-based Question Answering framework where each question is answered by the machine by using a joint distance metric that takes the structures and relations preserved in the knowledge graph embedding spaces. The KG embedding space is a low dimensional vector representation of all the relations and entities in a KG. They use attention-based bidirectional LSTM models to perform the relation
and entity representation learning.

Another method, TransE-QA \cite{10.1145/3390557.3394296}, solves the problem of simple question answering by combining the knowledge graph representation learning algorithm and the question distributed representation method, by providing the existing question and knowledge graph as input for joint training using the deep learning framework of Tensorflow. They perform their evaluation on the FB5M dataset, which is a subset of Freebase. They visualize the process using a web-based system based on the Flask framework.
% complex question answering

Recently, the focus has shifted towards complex questions comprising of multiple entities and relations.
Existing techniques struggle to match the human-level understanding of questions, even in well-researched topics such as general domain factual question answering. When a query becomes complex, the number of candidates grows exponentially with the number of query components and joins. 

TextRay \cite{textray} is a complex question answering system that automatically translates a complex question to the matching query over the knowledge graph using the decompose-execute-join approach. They use a neural network-based semantic matching model that learns to score candidates for partial queries using implicit supervision from question-answer pairs. TextRay works well on complex questions and gives comparable results on simple questions. Abujabal et al. \cite{10.1145/3038912.3052583} proposed an automated template generation model, namely QUINT, for complex question answering that supports two kinds of templates, i.e., query template and question template based on standard dependency parse trees. The candidate queries are ranked using the random forest classifier. Bio-SODA, proposed by Sima et al  \cite{10.1145/3468791.3469119}, uses a generic graph-based approach for translating user questions to a ranked list of SPARQL candidates queries in scientific datasets without the use of any training data. They rank their queries by combining semantic and syntactic similarity along with node centrality in knowledge graphs.

Another approach that can be quickly adapted to new domains is the Frankenstein \cite{frankenstein} framework relying on machine learning techniques for dynamically selecting suitable QA components and composing QA pipelines based on the input question. Frankenstein uses existing components available in the Question Answering research community into a single platform. 

Our approach builds a similar free text graph from Wikipedia as presented in DELFT \cite{delft}. Delft builds a high coverage and dense free-text knowledge graph, using natural language sentences as edges. To answer questions, delft grounds the question into the related subgraph connecting entities with free-text graph edges and then uses a graph neural network to represent, reason, and select the answer using evidence from both free-text and the graph structure.

Recent advances have enabled the discovery of relevant structured sources of knowledge increasingly achievable. Many modern systems take the existing data with a particular structure or schema and re-use it in a different form. These applications start with an understanding of how data will be used and viewed and create mappings between the schema of the knowledge graphs and the target entities. Knowledge graphs incorporate a wealth of sophisticated knowledge about queries and query manipulation. 

Query discovery is achieved using schema mapping. Schema integration techniques focus on creation of the integrated schemas and creation of queries. A common use of mappings is in query reformulation, commonly referred to as data integration, where queries on a target schema are reformulated, using the mappings, into queries on a source schema.  Clio \cite{renne2000,Fagin2009} is a schema mapping framework, that uses a set of value correspondences (or matchings) that describe how to populate a single attribute of the target schema to find the mapping query. Clio simplifies information integration, by providing tools that help users convert data between representations. Clio mappings assume that given two schemas to map data from the first to the second, the first schema is a source schema, and the second as a target schema. Relation mapping to generate sophisticated queries can be considered a similar problem. To answer a NLQ, we construct queries that specifies the required entities and relations.


\section{Interactive Systems}
Despite extensive research, answering questions remains a difficult task. The user needs to have a deep understanding of each of the steps in a question answering pipeline. Building interactive systems give the user the flexibility to choose the correct answers from given suggestions. Most interactive systems exist for query completion or query suggestion techniques. Sapphire \cite{sapphire}, is one such tool, that helps users write syntactically and semantically correct SPARQL queries without prior knowledge of the queried datasets. Sapphire constructs SPARQL queries, and it removes ambiguity by involving the user directly in query composition. The approach provides autocomplete suggestions with a very low response time that guarantees an interactive experience for users. 

SPARKLIS \cite{sparklis}, a Semantic Web tool helps the users explore and query SPARQL endpoints by guiding them in the
interactive building of questions and answers, from simple ones to complex ones. The users do not need to be familiar with the vocabulary and the schema of the KG. This approach combines different search paradigms like Faceted Search, Query Builders and Natural Language Interfaces. 

Lissandrini et al \cite{x2q} proposed a system named X2Q, for exploring huge knowledge graphs that is both interactive and progressive. The user is guided through the exploration process using an example-based method, in which they first provide a group of entities as partial examples of the desired results, and the system gradually recommends reformulation. X2Q uses the example query paradigm and ranking functions to generate results in a flexible and expressive fashion. They incorporate the user's feedback in the ranking scores to filter the irrelevant suggestions.

Users of interactive systems expect these systems to exhibit behaviours that can be characterized as understanding what the user is looking for, what the user has done and what the user knows \cite{10.5555/1641579.1641586}. Interactive systems refine queries based on the user’s feedback. IMPROVE-QA's \cite{10.1145/3357384.3358059} framework returns answers based on a few feedback over the original answers given by the QA systems. It also enhances paraphrasing dictionaries to ensure a continuous-learning capability in improving QA systems to provide better interactivity and online performance.

\section{Relation Mapping}
One of the main challenges of question answering in knowledge graphs is how to identify which relation within a Knowledge Graph matches the keyword found in a Natural Language question. Researchers have addressed this problem using different approaches.

Mulang’ et al, had the first attempt in mapping keywords to relations in KGs using ReMatch \cite{rematch}. Rematch measures the semantic similarity between the keywords and the relations in KGs based on graph distances from Wordnet\cite{wordnet}. 

Several modern approaches perform both entity linking and relation mapping tasks. EARL \cite{earl} uses the Generalised Travelling Salesman problem and connection density-based machine learning approach between entity nodes in KG. Falcon \cite{falcon} performs joint entity and relation mapping of short text, leveraging several fundamental principles of English morphology and utilizing an extended knowledge graph created by merging entities and relations from DBpedia. Falcon 2.0 \cite{falcon2} utilizes the fundamentals of the initial implementations of Falcon over Wikidata. KBPearl \cite{kbpearl} takes an incomplete KG and a large corpus of text as input to populate the KG. It then employs a semantic graph-based approach to utilize the context knowledge of the facts and the side information inferred from the source text in a global coherence and determine the best results by finding the densest subgraph.

Most works on entity and relation linking rely on the global coherence assumption, i.e., entities and relations within the same document are highly correlated with each other. Lin et al, proposed a technique named TENET \cite{tenet}, which relaxes the coherence assumption in the collective entity and relation mapping in an unsupervised manner as a minimum-cost coherence rooted tree cover problem. However, all these works only improve the output of relation mapping techniques. 

In comparison to all the other works in literature, we do not use sophisticated tools or machine learning models for relation mapping. In ReMLOFT, we investigate the method to map the keywords in the question to the information extracted in free-text sentences as indirect relations between entities which ensures the enhancement and population of candidate relations. ReMLOFT uses the context of keywords for finding relations and does not require training data. In addition, ReMLOFT also provides a dictionary with the most frequent keywords that define the context of a relation in the knowledge graph. ReMLOFT also interacts with the user to provide better candidate relations which helps the user identify semantically related relations to build complex SPARQL queries.


